{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d552bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive (4)\\BNBUSDT.csv\n",
      "archive (4)\\BNBUSDT_norm.csv\n",
      "archive (4)\\BTCUSDT.csv\n",
      "archive (4)\\BTCUSDT_norm.csv\n",
      "archive (4)\\ETHUSDT.csv\n",
      "archive (4)\\ETHUSDT_norm.csv\n",
      "archive (4)\\XRPUSDT.csv\n",
      "archive (4)\\XRPUSDT_norm.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your local folder path\n",
    "path = \"archive (4)\"\n",
    "\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a455678",
   "metadata": {},
   "source": [
    "Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220c094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import X\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(1000)\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import json\n",
    "# os.system('clear')\n",
    "os.environ['MKL_DEBUG_CPU_TYPE'] = '5'  # use string, not export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Flatten, Conv1D, Conv2D,\n",
    "    MaxPooling1D, Activation, Concatenate, LSTM\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorboardX import SummaryWriter  # external library, ok if installed\n",
    "\n",
    "# Set seeds\n",
    "random.seed(2002)\n",
    "np.random.seed(32)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "# Set channels first\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "\n",
    "class CustomEnv:\n",
    "    \"\"\"A custom Bitcoin trading environment\"\"\"\n",
    "    def __init__(self, df, df_normalized, initial_balance=1000,\n",
    "                 stocks=['USDCUSDT', 'BTCUSDT', 'BNBBTC', 'BNBBTC'],\n",
    "                 lookback_window_size=50, model=''):\n",
    "        self.xarray = df_normalized  # Normalized dataset\n",
    "        self.df = df                 # Raw dataset\n",
    "        self.df_total_steps = self.xarray.shape[0]\n",
    "        self.initial_balance = initial_balance\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.normalize_value = 40000\n",
    "        self.weights = [1] + [0] * (self.xarray.shape[2] - 1)\n",
    "        self.quants = [0] * self.xarray.shape[2]\n",
    "        self.quants_ubah = [0] * self.xarray.shape[2]\n",
    "        self.cash = 0\n",
    "        self.stocks = stocks\n",
    "        self.market_state = dict.fromkeys(self.stocks)\n",
    "        self.model = model\n",
    "        self.ubah = initial_balance\n",
    "\n",
    "        self.orders_history = deque(maxlen=self.lookback_window_size)\n",
    "        self.market_history = deque(maxlen=self.lookback_window_size)\n",
    "\n",
    "    def reset(self, env_steps_size=0):\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.prev_net_worth = self.initial_balance\n",
    "        self.weights = [1] + [0] * (self.xarray.shape[2] - 1)\n",
    "        self.quants = [0] * self.xarray.shape[2]\n",
    "        self.quants_ubah = [0] * self.xarray.shape[2]\n",
    "        self.short_sell = [1, 1, 1]\n",
    "        self.cash = self.initial_balance\n",
    "        self.ubah = self.initial_balance\n",
    "\n",
    "        if env_steps_size > 0:\n",
    "            self.start_step = random.randint(self.lookback_window_size,\n",
    "                                             self.df_total_steps - env_steps_size)\n",
    "            self.end_step = self.start_step + env_steps_size\n",
    "        else:\n",
    "            self.start_step = self.lookback_window_size\n",
    "            self.end_step = self.df_total_steps\n",
    "\n",
    "        self.current_step = self.start_step\n",
    "\n",
    "        # Buy and Hold quantities\n",
    "        self.quants_ubah = [\n",
    "            (self.initial_balance / len(self.weights)) /\n",
    "            np.array([self.df[self.current_step, 2, x] for x in range(len(self.stocks))])\n",
    "        ]\n",
    "\n",
    "        # Init orders history\n",
    "        for i in reversed(range(self.lookback_window_size)):\n",
    "            current_step = self.current_step - i\n",
    "            self.orders_history.append(\n",
    "                [self.net_worth / self.normalize_value,\n",
    "                 self.cash / self.normalize_value] +\n",
    "                [number for number in self.quants] +\n",
    "                [number for number in self.weights]\n",
    "            )\n",
    "\n",
    "        # Init market history\n",
    "        for j in range(len(self.stocks)):\n",
    "            self.market_state[str(j)] = deque(maxlen=self.lookback_window_size)\n",
    "            for i in reversed(range(self.lookback_window_size)):\n",
    "                current_step = self.current_step - i\n",
    "                self.market_state[str(j)].append(self.xarray[current_step, :, j])\n",
    "\n",
    "        if self.model == \"EIIE\":\n",
    "            state = np.stack([self.market_state[str(x)] for x in range(len(self.stocks))])\n",
    "        else:\n",
    "            state = np.concatenate(\n",
    "                [self.market_state[str(x)] for x in range(len(self.stocks))], axis=1\n",
    "            )\n",
    "            state = np.concatenate((state, self.orders_history), axis=1)\n",
    "\n",
    "        return state, self.orders_history\n",
    "\n",
    "    def _next_observation(self):\n",
    "        for j in range(len(self.stocks)):\n",
    "            self.market_state[str(j)].append(self.xarray[self.current_step, :, j])\n",
    "\n",
    "        if self.model == \"EIIE\":\n",
    "            obs = np.stack([self.market_state[str(x)] for x in range(len(self.stocks))])\n",
    "        else:\n",
    "            obs = np.concatenate(\n",
    "                [self.market_state[str(x)] for x in range(len(self.stocks))], axis=1\n",
    "            )\n",
    "            obs = np.concatenate((obs, self.orders_history), axis=1)\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def step(self, prediction):\n",
    "        prices_ant = np.array([self.df[self.current_step, 2, x] for x in range(len(self.stocks))])\n",
    "        self.current_step += 1\n",
    "        prices = np.array([self.df[self.current_step, 2, x] for x in range(len(self.stocks))])\n",
    "\n",
    "        self.balance = self.cash + np.dot(prices[1:], self.quants[1:])\n",
    "        quants_ant = self.quants\n",
    "\n",
    "        self.quants = [self.balance * prediction[x] / prices[x] for x in range(len(self.stocks))]\n",
    "\n",
    "        tax = np.sum(\n",
    "            abs(np.dot(np.array(self.quants), prices) -\n",
    "                np.dot(np.array(quants_ant), prices_ant))\n",
    "        ) * 0.001\n",
    "\n",
    "        self.cash = self.quants[0] * prices[0]\n",
    "        self.prev_net_worth = self.net_worth\n",
    "        self.net_worth = np.dot(self.quants, prices) - tax\n",
    "\n",
    "        self.orders_history.append(\n",
    "            [self.net_worth / self.normalize_value,\n",
    "             self.cash / self.normalize_value] +\n",
    "            [number / self.normalize_value for number in self.quants] +\n",
    "            prediction.tolist()\n",
    "        )\n",
    "\n",
    "        reward = np.log(self.net_worth / self.prev_net_worth)\n",
    "\n",
    "        done = self.net_worth <= self.initial_balance / 2\n",
    "        obs = self._next_observation()\n",
    "\n",
    "        return obs, self.orders_history, reward, done, prices\n",
    "\n",
    "    def render(self):\n",
    "        print(f'Step: {self.current_step}, Net Worth: {self.net_worth}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab544d5",
   "metadata": {},
   "source": [
    "Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0878c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAgent:\n",
    "    # A custom Bitcoin trading agent\n",
    "    def __init__(self, lookback_window_size=50, lr=0.00005, epochs=1, stocks=[], optimizer=Adam, batch_size=32, model=\"\", shape=[], depth=0, comment=\"\"):\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.model = model\n",
    "        self.comment = comment\n",
    "        self.depth = depth\n",
    "        self.stocks = stocks\n",
    "        self.shape = shape\n",
    "\n",
    "        # Action space goes from 0 to the number of assets in the portfolio\n",
    "        self.action_space = np.array(range(0, len(self.stocks)))\n",
    "\n",
    "        # Folder to save models\n",
    "        self.log_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M\") + \"_Crypto_trader\"\n",
    "\n",
    "        # State size contains Market + Orders + Indicators history for the last lookback_window_size steps\n",
    "        if self.model == \"EIIE\":\n",
    "            self.state_size = (len(stocks), lookback_window_size, self.shape[1])\n",
    "        else:\n",
    "            self.state_size = (lookback_window_size, self.shape[1] * self.shape[2] + 2 + 2 * self.shape[2])  # OHLC info + market + indicators\n",
    "\n",
    "        # Neural Networks configuration\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Create shared Actor-Critic network model\n",
    "        self.Actor = self.Critic = Shared_Model(\n",
    "            input_shape=self.state_size,\n",
    "            action_space=self.action_space.shape[0],\n",
    "            lr=self.lr,\n",
    "            optimizer=self.optimizer,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "    # Create TensorBoard writer\n",
    "    def create_writer(self, initial_balance, normalize_value, train_episodes):\n",
    "        self.replay_count = 0\n",
    "        self.writer = SummaryWriter('runs/' + self.log_name)\n",
    "\n",
    "        # Create folder to save models\n",
    "        if not os.path.exists(self.log_name):\n",
    "            os.makedirs(self.log_name)\n",
    "\n",
    "        self.start_training_log(initial_balance, normalize_value, train_episodes)\n",
    "\n",
    "    def start_training_log(self, initial_balance, normalize_value, train_episodes):\n",
    "        # Save training parameters to Parameters.json for future use\n",
    "        current_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "        params = {\n",
    "            \"training start\": current_date,\n",
    "            \"initial balance\": initial_balance,\n",
    "            \"training episodes\": train_episodes,\n",
    "            \"lookback window size\": self.lookback_window_size,\n",
    "            \"depth\": self.depth,\n",
    "            \"lr\": self.lr,\n",
    "            \"epochs\": self.epochs,\n",
    "            \"batch size\": self.batch_size,\n",
    "            \"normalize value\": normalize_value,\n",
    "            \"model\": self.model,\n",
    "            \"comment\": self.comment,\n",
    "            \"saving time\": \"\",\n",
    "            \"Actor name\": \"\",\n",
    "            \"Critic name\": \"\",\n",
    "        }\n",
    "        with open(self.log_name + \"/Parameters.json\", \"w\") as write_file:\n",
    "            json.dump(params, write_file, indent=4)\n",
    "\n",
    "    def get_gaes(self, rewards, dones, values, next_values, gamma=0.99, lamda=0.95, normalize=True):\n",
    "        deltas = [r + gamma * (1 - d) * nv - v for r, d, nv, v in zip(rewards, dones, next_values, values)]\n",
    "        deltas = np.stack(deltas)\n",
    "        gaes = copy.deepcopy(deltas)\n",
    "        for t in reversed(range(len(deltas) - 1)):\n",
    "            gaes[t] = gaes[t] + (1 - dones[t]) * gamma * lamda * gaes[t + 1]\n",
    "\n",
    "        target = gaes + values\n",
    "        if normalize:\n",
    "            gaes = (gaes - gaes.mean()) / (gaes.std() + 1e-8)\n",
    "        return np.vstack(gaes), np.vstack(target)\n",
    "\n",
    "    def replay(self, states, orders, rewards, predictions, dones, next_states, orders_history):\n",
    "        # Reshape memory to a format suitable for training\n",
    "        states = np.vstack(states)\n",
    "        order = np.vstack(orders)\n",
    "        next_states = np.vstack(next_states)\n",
    "        orders_history = np.vstack(orders_history)\n",
    "        predictions = np.vstack(predictions)\n",
    "\n",
    "        # Get Critic predictions\n",
    "        if self.model == \"EIIE\":\n",
    "            values = self.Critic.critic_predict(states, np.expand_dims(order, axis=1))\n",
    "        else:\n",
    "            values = self.Critic.critic_predict(states, np.expand_dims(np.expand_dims(order, axis=0), axis=0))\n",
    "\n",
    "        next_values = self.Critic.critic_predict(next_states, np.expand_dims(orders_history, axis=1))\n",
    "\n",
    "        # Compute advantages\n",
    "        advantages, target = self.get_gaes(rewards, dones, np.squeeze(values), np.squeeze(next_values))\n",
    "\n",
    "        # Stack everything into numpy arrays\n",
    "        y_true = np.hstack([advantages, predictions])\n",
    "\n",
    "        # Train Actor and Critic networks\n",
    "        if self.model == \"EIIE\":\n",
    "            a_loss = self.Actor.Actor.fit([states, np.expand_dims(order, axis=1)], y_true,\n",
    "                                          epochs=self.epochs, verbose=0, shuffle=True, batch_size=self.batch_size)\n",
    "            c_loss = self.Critic.Critic.fit([states, np.expand_dims(order, axis=1)], target,\n",
    "                                            epochs=self.epochs, verbose=0, shuffle=True, batch_size=self.batch_size)\n",
    "        else:\n",
    "            a_loss = self.Actor.Actor.fit(states, y_true,\n",
    "                                          epochs=self.epochs, verbose=0, shuffle=True, batch_size=self.batch_size)\n",
    "            c_loss = self.Critic.Critic.fit(states, target,\n",
    "                                            epochs=self.epochs, verbose=0, shuffle=True, batch_size=self.batch_size)\n",
    "\n",
    "        self.writer.add_scalar('Data/actor_loss_per_replay', np.sum(a_loss.history['loss']), self.replay_count)\n",
    "        self.writer.add_scalar('Data/critic_loss_per_replay', np.sum(c_loss.history['loss']), self.replay_count)\n",
    "        self.replay_count += 1\n",
    "\n",
    "        return np.sum(a_loss.history['loss']), np.sum(c_loss.history['loss'])\n",
    "\n",
    "    def act(self, state, order):\n",
    "        # Use the neural network to predict the next action\n",
    "        prediction = self.Actor.actor_predict(np.expand_dims(state, axis=0),\n",
    "                                              np.expand_dims(np.expand_dims(order, axis=0), axis=0))[0]\n",
    "        return prediction\n",
    "\n",
    "    def save(self, name=\"Crypto_trader\", score=\"\", args=[]):\n",
    "        # Save Actor and Critic model weights\n",
    "        self.Actor.Actor.save_weights(f\"{self.log_name}/{score}_{name}_Actor.h5\")\n",
    "        self.Critic.Critic.save_weights(f\"{self.log_name}/{score}_{name}_Critic.h5\")\n",
    "\n",
    "        # Update JSON log with model details\n",
    "        if score != \"\":\n",
    "            with open(self.log_name + \"/Parameters.json\", \"r\") as json_file:\n",
    "                params = json.load(json_file)\n",
    "            params[\"saving time\"] = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "            params[\"Actor name\"] = f\"{score}_{name}_Actor.h5\"\n",
    "            params[\"Critic name\"] = f\"{score}_{name}_Critic.h5\"\n",
    "            with open(self.log_name + \"/Parameters.json\", \"w\") as write_file:\n",
    "                json.dump(params, write_file, indent=4)\n",
    "\n",
    "        # Append run arguments to log file\n",
    "        if len(args) > 0:\n",
    "            with open(f\"{self.log_name}/log.txt\", \"a+\") as log:\n",
    "                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                arguments = \"\"\n",
    "                for arg in args:\n",
    "                    arguments += f\", {arg}\"\n",
    "                log.write(f\"{current_time}{arguments}\\n\")\n",
    "\n",
    "    def load(self, folder, name):\n",
    "        # Load Actor and Critic model weights\n",
    "        self.Actor.Actor.load_weights(os.path.join(folder, f\"{name}_Actor.h5\"))\n",
    "        self.Critic.Critic.load_weights(os.path.join(folder, f\"{name}_Critic.h5\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fc0d8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
